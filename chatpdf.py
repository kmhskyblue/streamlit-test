import streamlit as st
import openai
import PyPDF2
import faiss
import os
import tempfile

from typing import List
from uuid import uuid4

st.set_page_config(page_title="GPT ì›¹ì•± with PDF Chat", layout="wide")

# -------------------------------
# API Key ì…ë ¥
# -------------------------------
st.sidebar.title("ğŸ” API Key ì„¤ì •")
if "api_key" not in st.session_state:
    st.session_state.api_key = ""

api_key_input = st.sidebar.text_input("OpenAI API Key", type="password")
if api_key_input:
    st.session_state.api_key = api_key_input

# -------------------------------
# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
# -------------------------------
if "chat_history" not in st.session_state:
    st.session_state.chat_history = [
        {"role": "system", "content": "ë‹¹ì‹ ì€ ì¹œì ˆí•œ AI ì±—ë´‡ì…ë‹ˆë‹¤."}
    ]
if "pdf_index" not in st.session_state:
    st.session_state.pdf_index = None
if "pdf_chunks" not in st.session_state:
    st.session_state.pdf_chunks = []
if "pdf_embeddings" not in st.session_state:
    st.session_state.pdf_embeddings = []

# -------------------------------
# í•¨ìˆ˜ ì •ì˜
# -------------------------------

def extract_text_from_pdf(file) -> str:
    pdf = PyPDF2.PdfReader(file)
    return "\n".join(page.extract_text() or "" for page in pdf.pages)

def chunk_text(text: str, max_tokens=500) -> List[str]:
    sentences = text.split(". ")
    chunks = []
    current_chunk = ""
    for sentence in sentences:
        if len(current_chunk + sentence) < max_tokens:
            current_chunk += sentence + ". "
        else:
            chunks.append(current_chunk.strip())
            current_chunk = sentence + ". "
    if current_chunk:
        chunks.append(current_chunk.strip())
    return chunks

def embed_chunks(chunks: List[str], api_key: str):
    openai.api_key = api_key
    response = openai.Embedding.create(
        input=chunks,
        model="text-embedding-3-small"
    )
    embeddings = [res["embedding"] for res in response["data"]]
    return embeddings

def create_faiss_index(embeddings: List[List[float]]):
    dim = len(embeddings[0])
    index = faiss.IndexFlatL2(dim)
    index.add(np.array(embeddings).astype("float32"))
    return index

def search_index(query, chunks, index, embeddings, api_key, k=3):
    openai.api_key = api_key
    query_embedding = openai.Embedding.create(
        input=[query],
        model="text-embedding-3-small"
    )["data"][0]["embedding"]
    D, I = index.search(np.array([query_embedding]).astype("float32"), k)
    relevant_chunks = [chunks[i] for i in I[0]]
    return "\n\n".join(relevant_chunks)

def ask_pdf_bot(query, context, api_key):
    messages = [
        {"role": "system", "content": "ë‹¤ìŒ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”:\n" + context},
        {"role": "user", "content": query}
    ]
    openai.api_key = api_key
    response = openai.ChatCompletion.create(
        model="gpt-4-1106-preview",
        messages=messages
    )
    return response.choices[0].message.content.strip()

# -------------------------------
# í˜ì´ì§€ êµ¬ì„±
# -------------------------------
tab1, tab2, tab3 = st.tabs(["ğŸ§  Ask GPT", "ğŸ’¬ Chat GPT", "ğŸ“„ ChatPDF"])

# 1. Ask GPT
with tab1:
    st.header("ğŸ§  GPTì— ì§ˆë¬¸í•˜ê¸°")

    @st.cache_data(show_spinner=False)
    def get_single_response(prompt, api_key):
        openai.api_key = api_key
        response = openai.ChatCompletion.create(
            model="gpt-4-1106-preview",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ì¹œì ˆí•œ AI ë¹„ì„œì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ]
        )
        return response.choices[0].message.content.strip()

    if not st.session_state.api_key:
        st.warning("API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    else:
        question = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”")
        if question:
            with st.spinner("GPT ì‘ë‹µ ìƒì„± ì¤‘..."):
                answer = get_single_response(question, st.session_state.api_key)
                st.markdown("### âœ… GPT ì‘ë‹µ")
                st.write(answer)

# 2. Chat GPT
with tab2:
    st.header("ğŸ’¬ GPTì™€ ëŒ€í™”í•˜ê¸°")
    col1, col2 = st.columns([6, 1])
    with col2:
        if st.button("ğŸ§¹ Clear Chat"):
            st.session_state.chat_history = [
                {"role": "system", "content": "ë‹¹ì‹ ì€ ì¹œì ˆí•œ AI ì±—ë´‡ì…ë‹ˆë‹¤."}
            ]
            st.rerun()

    if not st.session_state.api_key:
        st.warning("API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    else:
        user_input = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”")
        if user_input:
            st.session_state.chat_history.append({"role": "user", "content": user_input})
            with st.spinner("GPT ì‘ë‹µ ì¤‘..."):
                openai.api_key = st.session_state.api_key
                response = openai.ChatCompletion.create(
                    model="gpt-4-1106-preview",
                    messages=st.session_state.chat_history
                )
                reply = response.choices[0].message.content.strip()
                st.session_state.chat_history.append({"role": "assistant", "content": reply})

        for msg in st.session_state.chat_history[1:]:
            st.chat_message(msg["role"]).write(msg["content"])

# 3. ChatPDF
with tab3:
    import numpy as np

    st.header("ğŸ“„ ChatPDF: PDF ê¸°ë°˜ ì±—ë´‡")
    uploaded_file = st.file_uploader("PDF íŒŒì¼ ì—…ë¡œë“œ", type=["pdf"])

    if st.button("ğŸ§¹ Clear PDF Vector Store"):
        st.session_state.pdf_index = None
        st.session_state.pdf_chunks = []
        st.session_state.pdf_embeddings = []
        st.success("PDF ë²¡í„° ì €ì¥ì†Œê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")

    if uploaded_file and st.session_state.api_key:
        with st.spinner("PDFë¥¼ ì²˜ë¦¬ ì¤‘..."):
            text = extract_text_from_pdf(uploaded_file)
            chunks = chunk_text(text)
            embeddings = embed_chunks(chunks, st.session_state.api_key)
            index = create_faiss_index(embeddings)

            st.session_state.pdf_chunks = chunks
            st.session_state.pdf_embeddings = embeddings
            st.session_state.pdf_index = index
            st.success(f"{len(chunks)}ê°œ ë¬¸ë‹¨ìœ¼ë¡œ ë¶„í• í•˜ì—¬ ì„ë² ë”© ì™„ë£Œ!")

    if st.session_state.pdf_index:
        query = st.text_input("PDFì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”")
        if query:
            with st.spinner("ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘..."):
                context = search_index(
                    query,
                    st.session_state.pdf_chunks,
                    st.session_state.pdf_index,
                    st.session_state.pdf_embeddings,
                    st.session_state.api_key
                )
                answer = ask_pdf_bot(query, context, st.session_state.api_key)
                st.markdown("### ğŸ“„ GPT ì‘ë‹µ")
                st.write(answer)
