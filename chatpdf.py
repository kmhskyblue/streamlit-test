import streamlit as st
from openai import OpenAI
import PyPDF2
import numpy as np
from typing import List

st.set_page_config(page_title="GPT ì›¹ì•±", layout="wide")

# --------------------------
# API Key ì…ë ¥
# --------------------------
st.sidebar.title("ğŸ” API Key ì„¤ì •")
if "api_key" not in st.session_state:
    st.session_state.api_key = ""

api_key_input = st.sidebar.text_input("OpenAI API Key", type="password")
if api_key_input:
    st.session_state.api_key = api_key_input

# --------------------------
# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
# --------------------------
if "chat_history" not in st.session_state:
    st.session_state.chat_history = [{"role": "system", "content": "ë‹¹ì‹ ì€ ì¹œì ˆí•œ AI ì±—ë´‡ì…ë‹ˆë‹¤."}]
if "pdf_chunks" not in st.session_state:
    st.session_state.pdf_chunks = []
if "pdf_embeddings" not in st.session_state:
    st.session_state.pdf_embeddings = []
if "api_key" not in st.session_state:
    st.session_state.api_key = ""
if "chatbot_history" not in st.session_state:
    st.session_state.chatbot_history = []

# --------------------------
# ìœ í‹¸ í•¨ìˆ˜ë“¤
# --------------------------
def get_client():
    return OpenAI(api_key=st.session_state.api_key)

def extract_text_from_pdf(file) -> str:
    reader = PyPDF2.PdfReader(file)
    return "\n".join([page.extract_text() or "" for page in reader.pages])

def chunk_text(text: str, max_tokens=500) -> List[str]:
    sentences = text.split(". ")
    chunks = []
    chunk = ""
    for sentence in sentences:
        if len(chunk + sentence) < max_tokens:
            chunk += sentence + ". "
        else:
            chunks.append(chunk.strip())
            chunk = sentence + ". "
    if chunk:
        chunks.append(chunk.strip())
    return chunks

def embed_chunks(chunks: List[str]):
    client = get_client()
    # ë¹ˆ ë¬¸ìì—´, None ì œê±°
    clean_chunks = [chunk for chunk in chunks if isinstance(chunk, str) and chunk.strip()]
    if not clean_chunks:
        raise ValueError("ì…ë ¥í•  ìœ íš¨í•œ í…ìŠ¤íŠ¸ ì²­í¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
    response = client.embeddings.create(
        input=clean_chunks,
        model="text-embedding-3-small"
    )
    return [item.embedding for item in response.data]

def cosine_similarity(a, b):
    a = np.array(a)
    b = np.array(b)
    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))

def search_similar_chunks(query: str, chunks: List[str], embeddings: List[List[float]], k=3):
    if not isinstance(query, str) or not query.strip():
        raise ValueError("QueryëŠ” ë¹„ì–´ìˆê±°ë‚˜ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    
    client = get_client()
    query_embedding = client.embeddings.create(
        input=[query],
        model="text-embedding-3-small"
    ).data[0].embedding
    
    similarities = [cosine_similarity(query_embedding, emb) for emb in embeddings]
    top_indices = np.argsort(similarities)[::-1][:k]
    return "\n\n".join([chunks[i] for i in top_indices])

def ask_pdf_bot(query: str, context: str):
    client = get_client()
    response = client.chat.completions.create(
        model="gpt-4-1106-preview",
        messages=[
            {"role": "system", "content": "ë‹¤ìŒ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”:\n" + context},
            {"role": "user", "content": query}
        ]
    )
    return response.choices[0].message.content.strip()

def get_single_response(prompt: str):
    client = get_client()
    response = client.chat.completions.create(
        model="gpt-4-1106-preview",
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ ì¹œì ˆí•œ AI ë¹„ì„œì…ë‹ˆë‹¤."},
            {"role": "user", "content": prompt}
        ]
    )
    return response.choices[0].message.content.strip()

# --------------------------
# íƒ­ UI êµ¬ì„±
# --------------------------
tab1, tab2, tab3, tab4 = st.tabs(["ğŸ§  Ask GPT", "ğŸ’¬ Chat", "ğŸ“„ ChatPDF", "ğŸ“š Chatbot"])

# --------------------------
# Tab 1: Ask GPT
# --------------------------
with tab1:
    st.header("ğŸ§  GPTì— ë‹¨ì¼ ì§ˆë¬¸")
    if not st.session_state.api_key:
        st.warning("API Keyë¥¼ ë¨¼ì € ì…ë ¥í•˜ì„¸ìš”.")
    else:
        user_prompt = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:")
        if user_prompt:
            with st.spinner("GPT ì‘ë‹µ ìƒì„± ì¤‘..."):
                response = get_single_response(user_prompt)
                st.markdown("### âœ… GPT ì‘ë‹µ")
                st.write(response)

# --------------------------
# Tab 2: Chat
# --------------------------
with tab2:
    st.header("ğŸ’¬ GPTì™€ ëŒ€í™”í•˜ê¸°")
    if not st.session_state.api_key:
        st.warning("API Keyë¥¼ ë¨¼ì € ì…ë ¥í•˜ì„¸ìš”.")
    else:
        col1, col2 = st.columns([6, 1])
        with col2:
            if st.button("ğŸ§¹ Clear", key="clear_button_chat"):
                st.session_state.chat_history = [{"role": "system", "content": "ë‹¹ì‹ ì€ ì¹œì ˆí•œ AI ì±—ë´‡ì…ë‹ˆë‹¤."}]
                st.rerun()

        user_msg = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”")
        if user_msg:
            st.session_state.chat_history.append({"role": "user", "content": user_msg})
            with st.spinner("ì‘ë‹µ ì¤‘..."):
                client = get_client()
                res = client.chat.completions.create(
                    model="gpt-4-1106-preview",
                    messages=st.session_state.chat_history
                )
                reply = res.choices[0].message.content.strip()
                st.session_state.chat_history.append({"role": "assistant", "content": reply})

        for msg in st.session_state.chat_history[1:]:
            st.chat_message(msg["role"]).write(msg["content"])

# --------------------------
# Tab 3: ChatPDF
# --------------------------
with tab3:
    st.header("ğŸ“„ PDF ì—…ë¡œë“œ í›„ ì§ˆë¬¸í•˜ê¸°")

    uploaded_file = st.file_uploader("PDF íŒŒì¼ ì—…ë¡œë“œ", type="pdf")
    if st.button("ğŸ§¹ Clear PDF", key="clear_button_chatpdf"):
        st.session_state.pdf_chunks = []
        st.session_state.pdf_embeddings = []
        st.success("PDF ë°ì´í„°ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")

    if uploaded_file and st.session_state.api_key:
        with st.spinner("PDF ë¶„ì„ ì¤‘..."):
            raw_text = extract_text_from_pdf(uploaded_file)
            chunks = chunk_text(raw_text)
            embeddings = embed_chunks(chunks)

            st.session_state.pdf_chunks = chunks
            st.session_state.pdf_embeddings = embeddings
            st.success(f"{len(chunks)}ê°œì˜ ì²­í¬ë¡œ ë¶„í•  ë° ì„ë² ë”© ì™„ë£Œ!")

    if st.session_state.pdf_chunks:
        query = st.text_input("PDF ë‚´ìš© ê¸°ë°˜ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:")
        if query:
            with st.spinner("ì‘ë‹µ ìƒì„± ì¤‘..."):
                context = search_similar_chunks(query, st.session_state.pdf_chunks, st.session_state.pdf_embeddings)
                answer = ask_pdf_bot(query, context)
                st.markdown("### ğŸ“„ GPT ì‘ë‹µ")
                st.write(answer)

def load_rules():
    with open("library_rules.txt", "r", encoding="utf-8") as f:
        return f.read()

library_rules = load_rules()

# --------------------------
# Tab 4: Chatbot
# --------------------------
with tab4:
    st.header("ğŸ“š êµ­ë¦½ë¶€ê²½ëŒ€í•™êµ ë„ì„œê´€ ì±—ë´‡")

    if not st.session_state.api_key:
        st.warning("API Keyë¥¼ ë¨¼ì € ì…ë ¥í•˜ì„¸ìš”.")
    else:
        col1, col2 = st.columns([6, 1])
        with col2:
            if st.button("ğŸ§¹ Clear", key="clear_button_chatbot"):
                st.session_state.chatbot_history = []
                st.rerun()

        user_q = st.chat_input("ë„ì„œê´€ì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì„ ì…ë ¥í•˜ì„¸ìš”")
        if user_q:
            client = OpenAI(api_key=st.session_state.api_key)
            st.session_state.chatbot_history.append({"role": "user", "content": user_q})

            with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
                response = client.chat.completions.create(
                    model="gpt-4-1106-preview",
                    messages=[
                        {"role": "system", "content": f"ë‹¤ìŒ êµ­ë¦½ë¶€ê²½ëŒ€í•™êµ ë„ì„œê´€ ê·œì •ì„ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”:\n{library_rules}"},
                        *st.session_state.chatbot_history
                    ]
                )
                answer = response.choices[0].message.content.strip()
                st.session_state.chatbot_history.append({"role": "assistant", "content": answer})

        for msg in st.session_state.chatbot_history:
            st.chat_message(msg["role"]).write(msg["content"])
