import streamlit as st
import openai import OpenAI
import PyPDF2
import numpy as np

from typing import List

st.set_page_config(page_title="GPT ì›¹ì•± with PDF Chat", layout="wide")

# -------------------------------
# API Key ì…ë ¥
# -------------------------------
st.sidebar.title("ğŸ” API Key ì„¤ì •")
if "api_key" not in st.session_state:
    st.session_state.api_key = ""

api_key_input = st.sidebar.text_input("OpenAI API Key", type="password")
if api_key_input:
    st.session_state.api_key = api_key_input

# -------------------------------
# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
# -------------------------------
if "chat_history" not in st.session_state:
    st.session_state.chat_history = [
        {"role": "system", "content": "ë‹¹ì‹ ì€ ì¹œì ˆí•œ AI ì±—ë´‡ì…ë‹ˆë‹¤."}
    ]
if "pdf_chunks" not in st.session_state:
    st.session_state.pdf_chunks = []
if "pdf_embeddings" not in st.session_state:
    st.session_state.pdf_embeddings = []

# -------------------------------
# ê³µí†µ í•¨ìˆ˜
# -------------------------------
def extract_text_from_pdf(file) -> str:
    pdf = PyPDF2.PdfReader(file)
    return "\n".join(page.extract_text() or "" for page in pdf.pages)

def chunk_text(text: str, max_tokens=500) -> List[str]:
    sentences = text.split(". ")
    chunks = []
    current_chunk = ""
    for sentence in sentences:
        if len(current_chunk + sentence) < max_tokens:
            current_chunk += sentence + ". "
        else:
            chunks.append(current_chunk.strip())
            current_chunk = sentence + ". "
    if current_chunk:
        chunks.append(current_chunk.strip())
    return chunks

def embed_chunks(chunks: List[str], api_key: str):
    openai.api_key = api_key
    response = openai.Embedding.create(
        input=chunks,
        model="text-embedding-3-small"
    )
    return [res["embedding"] for res in response["data"]]

def cosine_similarity(a, b):
    a = np.array(a)
    b = np.array(b)
    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))

def search_similar_chunks(query, chunks, embeddings, api_key, k=3):
    openai.api_key = api_key
    query_embedding = openai.Embedding.create(
        input=[query],
        model="text-embedding-3-small"
    )["data"][0]["embedding"]
    sims = [cosine_similarity(query_embedding, emb) for emb in embeddings]
    top_indices = np.argsort(sims)[::-1][:k]
    return "\n\n".join([chunks[i] for i in top_indices])

def ask_pdf_bot(query, context, api_key):
    messages = [
        {"role": "system", "content": "ë‹¤ìŒ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”:\n" + context},
        {"role": "user", "content": query}
    ]
    openai.api_key = api_key
    response = openai.ChatCompletion.create(
        model="gpt-4-1106-preview",
        messages=messages
    )
    return response.choices[0].message.content.strip()

# -------------------------------
# íƒ­ êµ¬ì„±
# -------------------------------
tab1, tab2, tab3 = st.tabs(["ğŸ§  Ask GPT", "ğŸ’¬ Chat GPT", "ğŸ“„ ChatPDF"])

# 1. Ask GPT
with tab1:
    st.header("ğŸ§  GPTì— ì§ˆë¬¸í•˜ê¸°")

    @st.cache_data(show_spinner=False)
    def get_single_response(prompt, api_key):
        openai.api_key = api_key
        response = openai.ChatCompletion.create(
            model="gpt-4-1106-preview",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ì¹œì ˆí•œ AI ë¹„ì„œì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ]
        )
        return response.choices[0].message.content.strip()

    if not st.session_state.api_key:
        st.warning("API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    else:
        question = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”")
        if question:
            with st.spinner("GPT ì‘ë‹µ ìƒì„± ì¤‘..."):
                answer = get_single_response(question, st.session_state.api_key)
                st.markdown("### âœ… GPT ì‘ë‹µ")
                st.write(answer)

# 2. Chat GPT
with tab2:
    st.header("ğŸ’¬ GPTì™€ ëŒ€í™”í•˜ê¸°")
    col1, col2 = st.columns([6, 1])
    with col2:
        if st.button("ğŸ§¹ Clear Chat"):
            st.session_state.chat_history = [
                {"role": "system", "content": "ë‹¹ì‹ ì€ ì¹œì ˆí•œ AI ì±—ë´‡ì…ë‹ˆë‹¤."}
            ]
            st.rerun()

    if not st.session_state.api_key:
        st.warning("API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    else:
        user_input = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”")
        if user_input:
            st.session_state.chat_history.append({"role": "user", "content": user_input})
            with st.spinner("GPT ì‘ë‹µ ì¤‘..."):
                openai.api_key = st.session_state.api_key
                response = openai.ChatCompletion.create(
                    model="gpt-4-1106-preview",
                    messages=st.session_state.chat_history
                )
                reply = response.choices[0].message.content.strip()
                st.session_state.chat_history.append({"role": "assistant", "content": reply})

        for msg in st.session_state.chat_history[1:]:
            st.chat_message(msg["role"]).write(msg["content"])

# 3. ChatPDF
with tab3:
    st.header("ğŸ“„ ChatPDF: PDF ê¸°ë°˜ ì±—ë´‡")

    uploaded_file = st.file_uploader("PDF íŒŒì¼ ì—…ë¡œë“œ", type=["pdf"])
    if st.button("ğŸ§¹ Clear PDF Data"):
        st.session_state.pdf_chunks = []
        st.session_state.pdf_embeddings = []
        st.success("PDF ë°ì´í„° ì´ˆê¸°í™” ì™„ë£Œ!")

    if uploaded_file and st.session_state.api_key:
        with st.spinner("PDF ë¶„ì„ ì¤‘..."):
            text = extract_text_from_pdf(uploaded_file)
            chunks = chunk_text(text)
            embeddings = embed_chunks(chunks, st.session_state.api_key)

            st.session_state.pdf_chunks = chunks
            st.session_state.pdf_embeddings = embeddings
            st.success(f"{len(chunks)}ê°œ ë¬¸ë‹¨ ë¶„ì„ ì™„ë£Œ!")

    if st.session_state.pdf_chunks:
        query = st.text_input("PDFì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”")
        if query:
            with st.spinner("ì‘ë‹µ ìƒì„± ì¤‘..."):
                context = search_similar_chunks(
                    query,
                    st.session_state.pdf_chunks,
                    st.session_state.pdf_embeddings,
                    st.session_state.api_key
                )
                answer = ask_pdf_bot(query, context, st.session_state.api_key)
                st.markdown("### ğŸ“„ GPT ì‘ë‹µ")
                st.write(answer)
